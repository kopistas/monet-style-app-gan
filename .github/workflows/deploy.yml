name: Deploy Infrastructure and Applications

on:
  push:
    branches:
      - main
  workflow_dispatch:

env:
  DOCKER_REGISTRY: ghcr.io/${{ github.repository_owner }}
  TF_VERSION: "1.5.7"

jobs:
  terraform:
    name: Terraform
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Terraform Init
        working-directory: terraform
        env:
          DO_TOKEN: ${{ secrets.DO_TOKEN }}
          DO_SPACES_ACCESS_KEY: ${{ secrets.DO_SPACES_ACCESS_KEY }}
          DO_SPACES_SECRET_KEY: ${{ secrets.DO_SPACES_SECRET_KEY }}
          TF_VAR_do_token: ${{ secrets.DO_TOKEN }}
          AWS_ACCESS_KEY_ID: ${{ secrets.DO_SPACES_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.DO_SPACES_SECRET_KEY }}
        run: |
          terraform init -backend-config="access_key=$DO_SPACES_ACCESS_KEY" -backend-config="secret_key=$DO_SPACES_SECRET_KEY"

      - name: Terraform Plan
        working-directory: terraform
        env:
          DO_TOKEN: ${{ secrets.DO_TOKEN }}
          TF_VAR_do_token: ${{ secrets.DO_TOKEN }}
          TF_VAR_do_region: ${{ secrets.DO_REGION || 'nyc1' }}
          TF_VAR_do_spaces_region: ${{ secrets.DO_SPACES_REGION || 'nyc3' }}
          TF_VAR_do_spaces_name: ${{ secrets.DO_SPACES_NAME || 'monet-models' }}
          TF_VAR_do_spaces_access_key: ${{ secrets.DO_SPACES_ACCESS_KEY }}
          TF_VAR_do_spaces_secret_key: ${{ secrets.DO_SPACES_SECRET_KEY }}
          TF_VAR_app_domain: ${{ secrets.APP_DOMAIN || 'monet-app.example.com' }}
          TF_VAR_mlflow_domain: ${{ secrets.MLFLOW_DOMAIN || 'mlflow.example.com' }}
          TF_VAR_unsplash_api_key: ${{ secrets.UNSPLASH_API_KEY || '' }}
          TF_VAR_email_for_ssl: ${{ secrets.EMAIL_FOR_SSL || 'admin@example.com' }}
          TF_VAR_use_do_dns: ${{ secrets.USE_DO_DNS || 'false' }}
          TF_VAR_deploy_mlflow: ${{ secrets.DEPLOY_MLFLOW || 'false' }}
          TF_VAR_load_balancer_ip: ${{ secrets.LOAD_BALANCER_IP || '' }}
          TF_VAR_mlflow_username: ${{ secrets.MLFLOW_USERNAME || '' }}
          TF_VAR_mlflow_password: ${{ secrets.MLFLOW_PASSWORD || '' }}
        run: terraform plan -out=tfplan

      - name: Terraform Apply
        working-directory: terraform
        env:
          DO_TOKEN: ${{ secrets.DO_TOKEN }}
          TF_VAR_do_token: ${{ secrets.DO_TOKEN }}
          TF_VAR_do_spaces_access_key: ${{ secrets.DO_SPACES_ACCESS_KEY }}
          TF_VAR_do_spaces_secret_key: ${{ secrets.DO_SPACES_SECRET_KEY }}
          TF_VAR_do_region: ${{ secrets.DO_REGION || 'nyc1' }}
          TF_VAR_do_spaces_region: ${{ secrets.DO_SPACES_REGION || 'nyc3' }}
          TF_VAR_app_domain: ${{ secrets.APP_DOMAIN }}
          TF_VAR_mlflow_domain: ${{ secrets.MLFLOW_DOMAIN }}
          TF_VAR_deploy_mlflow: ${{ secrets.DEPLOY_MLFLOW || 'false' }}
          TF_VAR_load_balancer_ip: ${{ secrets.LOAD_BALANCER_IP || '' }}
          TF_VAR_mlflow_username: ${{ secrets.MLFLOW_USERNAME || '' }}
          TF_VAR_mlflow_password: ${{ secrets.MLFLOW_PASSWORD || '' }}
        run: terraform apply -auto-approve tfplan

      - name: Save Terraform Output and Update for Next Run
        working-directory: terraform
        run: |
          mkdir -p ../kubernetes/output
          
          # Add the load balancer IP to env vars for next terraform run
          if [ -n "$LOAD_BALANCER_IP" ]; then
            echo "TF_VAR_load_balancer_ip=$LOAD_BALANCER_IP" >> $GITHUB_ENV
          fi
          
          # Save raw output to a file
          terraform output -json > ../kubernetes/output/terraform-output-raw.json
          
          # Extract only the valid JSON part from the file
          echo "Cleaning Terraform output file..."
          # Look for the start of a JSON object and extract until the end of the JSON
          sed -n '/^{/,/^}$/p' ../kubernetes/output/terraform-output-raw.json > ../kubernetes/output/terraform-output.json
          
          # If that didn't work, try extracting everything between the first { and last }
          if ! jq empty ../kubernetes/output/terraform-output.json 2>/dev/null; then
            echo "Using alternative extraction method..."
            # Use awk to extract everything between first { and last }
            awk 'BEGIN{flag=0} /^{/{flag=1} flag{print} /^}$/{flag=0}' ../kubernetes/output/terraform-output-raw.json > ../kubernetes/output/terraform-output.json
          fi
          
          # If still not valid, try manual regeneration
          if ! jq empty ../kubernetes/output/terraform-output.json 2>/dev/null; then
            echo "Manual JSON extraction failed. Creating clean JSON..."
            # Manually create a clean JSON file with the required values
            echo "{" > ../kubernetes/output/terraform-output.json
            terraform output -raw spaces_region 2>/dev/null | xargs -I{} echo "  \"spaces_region\": { \"value\": \"{}\" }," >> ../kubernetes/output/terraform-output.json
            terraform output -raw spaces_bucket_name 2>/dev/null | xargs -I{} echo "  \"spaces_bucket_name\": { \"value\": \"{}\" }," >> ../kubernetes/output/terraform-output.json
            terraform output -raw dns_configuration 2>/dev/null | xargs -I{} echo "  \"dns_configuration\": { \"value\": \"{}\" }," >> ../kubernetes/output/terraform-output.json
            # Use load_balancer_ip from environment if available, otherwise empty
            if [ -n "$LOAD_BALANCER_IP" ]; then
              echo "  \"load_balancer_ip\": { \"value\": \"$LOAD_BALANCER_IP\" }" >> ../kubernetes/output/terraform-output.json
            else
              echo "  \"load_balancer_ip\": { \"value\": \"\" }" >> ../kubernetes/output/terraform-output.json
            fi
            echo "}" >> ../kubernetes/output/terraform-output.json
          fi
          
          # Show final file contents
          echo "Final Terraform output file contents:"
          cat ../kubernetes/output/terraform-output.json

      - name: Upload Kubernetes Config
        uses: actions/upload-artifact@v4
        with:
          name: kubeconfig
          path: terraform/kubeconfig.yaml
          retention-days: 1

      - name: Upload Terraform Output
        uses: actions/upload-artifact@v4
        with:
          name: terraform-output
          path: kubernetes/output/terraform-output.json
          retention-days: 1

  build-web-app:
    name: Build Web App
    runs-on: ubuntu-latest
    needs: terraform
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v2
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Build and push Docker image
        uses: docker/build-push-action@v3
        with:
          context: .
          file: kubernetes/web-app/Dockerfile
          push: true
          tags: ${{ env.DOCKER_REGISTRY }}/monet-web-app:${{ github.sha }},${{ env.DOCKER_REGISTRY }}/monet-web-app:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max

  deploy:
    name: Deploy Applications
    runs-on: ubuntu-latest
    needs: [terraform, build-web-app]
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Download Kubeconfig
        uses: actions/download-artifact@v4
        with:
          name: kubeconfig
          path: .kube

      - name: Download Terraform Output
        uses: actions/download-artifact@v4
        with:
          name: terraform-output
          path: kubernetes/output

      - name: Set up Kubernetes CLI
        uses: azure/setup-kubectl@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Export Environment Variables
        run: |
          # Check if output file exists
          echo "Validating Terraform output file..."
          if [ ! -f kubernetes/output/terraform-output.json ]; then
            echo "ERROR: Terraform output file not found. Terraform step likely failed."
            exit 1
          fi
          
          # Display file contents for debugging
          echo "Terraform output file contents:"
          cat kubernetes/output/terraform-output.json
          
          # If file exists but isn't valid JSON, try direct extraction of values
          if ! jq empty kubernetes/output/terraform-output.json 2>/dev/null; then
            echo "ERROR: Terraform output file is not valid JSON. Attempting direct extraction..."
            
            # Create a new clean file using grep to find the values
            echo "Creating clean JSON with extracted values..."
            echo "{" > kubernetes/output/terraform-output-clean.json
            
            # Extract spaces_region
            REGION_LINE=$(grep -A 3 "spaces_region" kubernetes/output/terraform-output.json | grep "value" | head -1)
            if [[ $REGION_LINE =~ \"value\":[[:space:]]*\"([^\"]+)\" ]]; then
              REGION="${BASH_REMATCH[1]}"
              echo "  \"spaces_region\": { \"value\": \"$REGION\" }," >> kubernetes/output/terraform-output-clean.json
            else
              echo "ERROR: Could not extract spaces_region value"
              exit 1
            fi
            
            # Extract spaces_bucket_name
            BUCKET_LINE=$(grep -A 3 "spaces_bucket_name" kubernetes/output/terraform-output.json | grep "value" | head -1)
            if [[ $BUCKET_LINE =~ \"value\":[[:space:]]*\"([^\"]+)\" ]]; then
              BUCKET="${BASH_REMATCH[1]}"
              echo "  \"spaces_bucket_name\": { \"value\": \"$BUCKET\" }," >> kubernetes/output/terraform-output-clean.json
            else
              echo "ERROR: Could not extract spaces_bucket_name value"
              exit 1
            fi
            
            # Extract dns_configuration
            DNS_LINE=$(grep -A 3 "dns_configuration" kubernetes/output/terraform-output.json | grep "value" | head -1)
            if [[ $DNS_LINE =~ \"value\":[[:space:]]*\"([^\"]+)\" ]]; then
              DNS="${BASH_REMATCH[1]}"
              echo "  \"dns_configuration\": { \"value\": \"$DNS\" }" >> kubernetes/output/terraform-output-clean.json
            else
              echo "No dns_configuration found, adding empty value"
              echo "  \"dns_configuration\": { \"value\": \"\" }" >> kubernetes/output/terraform-output-clean.json
            fi
            
            echo "}" >> kubernetes/output/terraform-output-clean.json
            
            # Replace the original file with the clean one
            mv kubernetes/output/terraform-output-clean.json kubernetes/output/terraform-output.json
            
            echo "Clean JSON file created:"
            cat kubernetes/output/terraform-output.json
          fi
          
          # Extract required values, fail if any are missing
          echo "Extracting values..."
          
          # Extract each value individually with detailed error checking
          DO_SPACES_REGION=$(jq -r '.spaces_region.value // empty' kubernetes/output/terraform-output.json)
          echo "Extracted DO_SPACES_REGION: '$DO_SPACES_REGION'"
          
          DO_SPACES_NAME=$(jq -r '.spaces_bucket_name.value // empty' kubernetes/output/terraform-output.json)
          echo "Extracted DO_SPACES_NAME: '$DO_SPACES_NAME'"
          
          DNS_CONFIG=$(jq -r '.dns_configuration.value // empty' kubernetes/output/terraform-output.json)
          echo "Extracted DNS_CONFIG: '$DNS_CONFIG'"
          
          # Fail if critical values are missing
          if [ -z "$DO_SPACES_REGION" ]; then
            echo "ERROR: spaces_region.value not found or empty in Terraform output"
            exit 1
          fi
          
          if [ -z "$DO_SPACES_NAME" ]; then
            echo "ERROR: spaces_bucket_name.value not found or empty in Terraform output"
            exit 1
          fi
          
          # Set environment variables
          echo "DO_SPACES_REGION=$DO_SPACES_REGION" >> $GITHUB_ENV
          echo "DO_SPACES_NAME=$DO_SPACES_NAME" >> $GITHUB_ENV
          echo "BACKEND_STORE_URI=file:///mlflow-db/mlflow.db" >> $GITHUB_ENV
          echo "DOCKER_REGISTRY=${DOCKER_REGISTRY}" >> $GITHUB_ENV
          echo "IMAGE_TAG=${{ github.sha }}" >> $GITHUB_ENV
          echo "APP_DOMAIN=${{ secrets.APP_DOMAIN }}" >> $GITHUB_ENV
          echo "MLFLOW_DOMAIN=${{ secrets.MLFLOW_DOMAIN }}" >> $GITHUB_ENV
          echo "EMAIL_FOR_SSL=${{ secrets.EMAIL_FOR_SSL || 'admin@example.com' }}" >> $GITHUB_ENV
          echo "UNSPLASH_API_KEY_BASE64=$(echo -n '${{ secrets.UNSPLASH_API_KEY || '' }}' | base64)" >> $GITHUB_ENV
          echo "DO_SPACES_ACCESS_KEY_BASE64=$(echo -n '${{ secrets.DO_SPACES_ACCESS_KEY }}' | base64)" >> $GITHUB_ENV
          echo "DO_SPACES_SECRET_KEY_BASE64=$(echo -n '${{ secrets.DO_SPACES_SECRET_KEY }}' | base64)" >> $GITHUB_ENV
          echo "MLFLOW_USERNAME_BASE64=$(echo -n '${{ secrets.MLFLOW_USERNAME || '' }}' | base64)" >> $GITHUB_ENV
          echo "MLFLOW_PASSWORD_BASE64=$(echo -n '${{ secrets.MLFLOW_PASSWORD || '' }}' | base64)" >> $GITHUB_ENV
          
          # Set DNS configuration 
          if [ -z "$DNS_CONFIG" ]; then
            echo "WARNING: dns_configuration.value not found or empty in Terraform output"
            echo "DNS_CONFIG=Missing in Terraform output" >> $GITHUB_ENV
          else
            echo "DNS_CONFIG=$DNS_CONFIG" >> $GITHUB_ENV
          fi

      - name: Display Environment Variables
        run: |
          echo "DO_SPACES_REGION: $DO_SPACES_REGION"
          echo "DO_SPACES_NAME: $DO_SPACES_NAME"
          echo "BACKEND_STORE_URI: $BACKEND_STORE_URI"
          echo "S3 ENDPOINT would be: https://$DO_SPACES_REGION.digitaloceanspaces.com"
          echo "DNS Configuration: $DNS_CONFIG"

      - name: Apply Kubernetes Manifests - Cert Manager
        run: |
          export KUBECONFIG=${{ github.workspace }}/.kube/kubeconfig.yaml
          
          # Apply cert-manager issuer
          envsubst < kubernetes/cert-manager/issuer.yaml | kubectl apply -f -

      - name: Get Load Balancer IP and Update DNS
        run: |
          export KUBECONFIG=${{ github.workspace }}/.kube/kubeconfig.yaml
          
          # Wait for NGINX Ingress controller service to get an external IP
          echo "Waiting for NGINX Ingress controller to get an external IP..."
          
          EXTERNAL_IP=""
          for i in {1..30}; do
            EXTERNAL_IP=$(kubectl get svc -n ingress-nginx nginx-ingress-ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null)
            
            if [ -n "$EXTERNAL_IP" ]; then
              echo "Load balancer has received IP: $EXTERNAL_IP"
              break
            fi
            
            echo "Waiting for load balancer external IP (attempt $i/30)..."
            sleep 10
          done
          
          if [ -z "$EXTERNAL_IP" ]; then
            echo "WARNING: Load balancer did not receive an external IP within timeout."
            echo "DNS records will need to be updated manually."
            exit 0
          fi
          
          echo "Load balancer IP: $EXTERNAL_IP"
          
          # Save the load balancer IP for future use
          echo "LOAD_BALANCER_IP=$EXTERNAL_IP" >> $GITHUB_ENV
          
          # For next Terraform runs, update DNS directly
          echo "For future Terraform runs, set load_balancer_ip=$EXTERNAL_IP"
          
          # Update DNS records using DigitalOcean API if use_do_dns is enabled
          if [[ "${{ secrets.USE_DO_DNS }}" == "true" ]]; then
            echo "Updating DNS records to point to $EXTERNAL_IP..."
            
            # Get domain IDs
            if [[ -n "${{ secrets.APP_DOMAIN }}" ]]; then
              echo "Updating ${{ secrets.APP_DOMAIN }} DNS record..."
              
              # Use the DO API to get record ID and update it
              RECORDS=$(curl -s -X GET \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer ${{ secrets.DO_TOKEN }}" \
                "https://api.digitalocean.com/v2/domains/${{ secrets.APP_DOMAIN }}/records")
              
              RECORD_ID=$(echo $RECORDS | jq -r '.domain_records[] | select(.type=="A" and .name=="@") | .id')
              
              if [[ -n "$RECORD_ID" ]]; then
                curl -s -X PUT \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer ${{ secrets.DO_TOKEN }}" \
                  -d "{\"data\":\"$EXTERNAL_IP\"}" \
                  "https://api.digitalocean.com/v2/domains/${{ secrets.APP_DOMAIN }}/records/$RECORD_ID"
                
                echo "Updated ${{ secrets.APP_DOMAIN }} DNS record to point to $EXTERNAL_IP"
              fi
              
              # Handle www subdomain
              RECORD_ID_WWW=$(echo $RECORDS | jq -r '.domain_records[] | select(.type=="A" and .name=="www") | .id')
              
              if [[ -n "$RECORD_ID_WWW" ]]; then
                # Update existing www record
                curl -s -X PUT \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer ${{ secrets.DO_TOKEN }}" \
                  -d "{\"data\":\"$EXTERNAL_IP\"}" \
                  "https://api.digitalocean.com/v2/domains/${{ secrets.APP_DOMAIN }}/records/$RECORD_ID_WWW"
                
                echo "Updated www.${{ secrets.APP_DOMAIN }} DNS record to point to $EXTERNAL_IP"
              else
                # Create new www record if it doesn't exist
                curl -s -X POST \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer ${{ secrets.DO_TOKEN }}" \
                  -d "{\"type\":\"A\",\"name\":\"www\",\"data\":\"$EXTERNAL_IP\",\"ttl\":300}" \
                  "https://api.digitalocean.com/v2/domains/${{ secrets.APP_DOMAIN }}/records"
                
                echo "Created new www.${{ secrets.APP_DOMAIN }} DNS record pointing to $EXTERNAL_IP"
              fi
            fi
            
            if [[ -n "${{ secrets.MLFLOW_DOMAIN }}" ]]; then
              echo "Updating ${{ secrets.MLFLOW_DOMAIN }} DNS record..."
              
              # Use the DO API to get record ID and update it
              RECORDS=$(curl -s -X GET \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer ${{ secrets.DO_TOKEN }}" \
                "https://api.digitalocean.com/v2/domains/${{ secrets.MLFLOW_DOMAIN }}/records")
              
              RECORD_ID=$(echo $RECORDS | jq -r '.domain_records[] | select(.type=="A" and .name=="@") | .id')
              
              if [[ -n "$RECORD_ID" ]]; then
                curl -s -X PUT \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer ${{ secrets.DO_TOKEN }}" \
                  -d "{\"data\":\"$EXTERNAL_IP\"}" \
                  "https://api.digitalocean.com/v2/domains/${{ secrets.MLFLOW_DOMAIN }}/records/$RECORD_ID"
                
                echo "Updated ${{ secrets.MLFLOW_DOMAIN }} DNS record to point to $EXTERNAL_IP"
              fi
            fi
          fi
          
      - name: Apply Kubernetes Manifests - MLflow
        run: |
          # Check if MLflow should be deployed
          if [[ "${{ secrets.DEPLOY_MLFLOW }}" == "true" ]]; then
            echo "Deploying MLflow as specified by DEPLOY_MLFLOW=true"
            export KUBECONFIG=${{ github.workspace }}/.kube/kubeconfig.yaml

            kubectl get storageclass
            
            # Create a basic auth secret for MLflow
            echo "Creating basic auth secret for MLflow..."
            # Generate htpasswd file with credentials from GitHub secrets
            htpasswd -bc /tmp/auth ${{ secrets.MLFLOW_USERNAME || 'mlflow-user' }} ${{ secrets.MLFLOW_PASSWORD || 'mlflow-password' }}
            # Create the secret in the MLflow namespace
            kubectl create namespace mlflow --dry-run=client -o yaml | kubectl apply -f -
            kubectl create secret generic basic-auth --from-file=/tmp/auth -n mlflow --dry-run=client -o yaml | kubectl apply -f -
            # Remove the temporary file for security
            rm /tmp/auth

            # Apply S3 credentials secret for MLflow
            echo "Applying S3 credentials secret for MLflow..."
            envsubst < kubernetes/mlflow/spaces-secret.yaml | kubectl apply -f -
            
            # Apply the MLflow certificate
            echo "Applying MLflow certificate..."
            envsubst < kubernetes/mlflow/certificate.yaml | kubectl apply -f -
            
            # Apply MLflow manifests
            envsubst < kubernetes/mlflow/deployment.yaml | kubectl apply -f -
            
            # Wait for MLflow PVC to be bound (give it up to 2 minutes)
            echo "Waiting for MLflow PVC to be provisioned..."
            kubectl wait --for=condition=Ready pvc/mlflow-database -n mlflow --timeout=120s || true
            
            # Force rollout of MLflow deployment to apply changes
            kubectl rollout restart deployment/mlflow -n mlflow
            
            # Wait for initial pod creation but don't fail pipeline if it's not ready yet
            echo "Waiting for initial MLflow pod creation..."
            kubectl rollout status deployment/mlflow -n mlflow --timeout=30s || true
            
            echo "MLflow deployment complete"
          else
            echo "MLflow deployment skipped (DEPLOY_MLFLOW=false or not set)"
            
            # Optionally, clean up MLflow resources if they exist
            export KUBECONFIG=${{ github.workspace }}/.kube/kubeconfig.yaml
            echo "Removing any existing MLflow deployment..."
            
            # Delete MLflow ingress
            kubectl delete ingress -n mlflow mlflow --ignore-not-found=true
            
            # Delete MLflow service
            kubectl delete service -n mlflow mlflow --ignore-not-found=true
            
            # Delete MLflow deployment
            kubectl delete deployment -n mlflow mlflow --ignore-not-found=true
            
            echo "MLflow resources have been removed (if they existed)"
          fi

      - name: Apply Kubernetes Manifests - Web App
        run: |
          export KUBECONFIG=${{ github.workspace }}/.kube/kubeconfig.yaml
          
          # Apply namespace first
          envsubst < kubernetes/web-app/namespace.yaml | kubectl apply -f -
          
          # Apply storage resources
          envsubst < kubernetes/web-app/storage.yaml | kubectl apply -f -
          
          # Apply secrets and configmaps
          envsubst < kubernetes/web-app/spaces-secret.yaml | kubectl apply -f -
          
          # Clean up any existing certificates first to ensure a fresh start
          echo "Cleaning up any existing certificates..."
          kubectl delete certificate -n monet-app monet-web-app-tls --ignore-not-found=true
          
          # Apply certificate resource first to give it more time to be processed
          echo "Applying web app certificate..."
          envsubst < kubernetes/cert-manager/certificate.yaml | kubectl apply -f -
          
          # Apply Web App manifests
          envsubst < kubernetes/web-app/deployment.yaml | kubectl apply -f -
          
          # Force rollout of web app deployment to apply changes
          kubectl rollout restart deployment/monet-web-app -n monet-app
          
          # Wait for initial pod creation but don't fail pipeline if it's not ready yet
          echo "Waiting for initial web app pod creation..."
          kubectl rollout status deployment/monet-web-app -n monet-app --timeout=60s || true
          
      - name: Verify Certificate and Debug Services
        run: |
          export KUBECONFIG=${{ github.workspace }}/.kube/kubeconfig.yaml
          
          # Wait for the certificate to be issued
          echo "Checking certificate status..."
          for i in {1..10}; do  # Increase retry attempts
            echo "Attempt $i to check certificate status..."
            kubectl get certificate -n monet-app monet-web-app-tls -o wide || true
            
            CERT_STATUS=$(kubectl get certificate -n monet-app monet-web-app-tls -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' 2>/dev/null || echo "")
            if [[ "$CERT_STATUS" == "True" ]]; then
              echo "Certificate is ready!"
              break
            fi
            
            # Check cert-manager logs for issues
            echo "Checking cert-manager controller logs for issues..."
            kubectl logs -n cert-manager -l app=cert-manager -c cert-manager --tail=20 || true
            
            # Check orders and challenges status
            echo "Checking ACME orders..."
            kubectl get orders.acme.cert-manager.io --all-namespaces || true
            
            echo "Checking ACME challenges..."
            kubectl get challenges.acme.cert-manager.io --all-namespaces || true
            
            # Check ACME solver pods
            echo "Checking ACME solver pods..."
            SOLVER_PODS=$(kubectl get pods --all-namespaces -l acme.cert-manager.io/http01-solver=true -o name)
            for pod in $SOLVER_PODS; do
              echo "Logs for $pod:"
              kubectl logs $pod --tail=20 || true
            done
            
            # Check ingress for challenges
            echo "ACME challenge ingress resources:"
            kubectl get ingress --all-namespaces -l acme.cert-manager.io/http01-solver=true || true
            
            # Attempt to manually curl challenge paths
            echo "Checking if challenges are reachable from the worker..."
            CHALLENGE_PATHS=$(kubectl get ingress --all-namespaces -l acme.cert-manager.io/http01-solver=true -o jsonpath='{range .items[*]}{range .spec.rules[*]}{range .http.paths[*]}{.path}{"\n"}{end}{end}{end}' 2>/dev/null || echo "")
            LOAD_BALANCER_IP=$(kubectl get svc -n ingress-nginx nginx-ingress-ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "")
            
            if [[ -n "$CHALLENGE_PATHS" && -n "$LOAD_BALANCER_IP" ]]; then
              for path in $CHALLENGE_PATHS; do
                echo "Checking challenge path: $path"
                curl -v -k "http://$LOAD_BALANCER_IP$path" || true
              done
            fi
            
            echo "Waiting for certificate to be issued (attempt $i/10)..."
            sleep 30  # Increase sleep to 30 seconds between attempts
          done
          
          # Check Certificate and Ingress status
          echo "Certificate details:"
          kubectl get certificate -n monet-app monet-web-app-tls -o yaml || true
          
          echo "Ingress details:"
          kubectl get ingress -n monet-app -o wide || true
          
          # Debug cert-manager issues
          echo "Checking cert-manager CRDs:"
          kubectl get clusterissuers.cert-manager.io || true
          
          # Check web app pod status
          echo "Web app pod status:"
          kubectl get pods -n monet-app || true
          
          # Look for any issues with the pod
          MISBEHAVING_POD=$(kubectl get pods -n monet-app -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
          if [[ -n "$MISBEHAVING_POD" ]]; then
            echo "Checking logs for pod $MISBEHAVING_POD:"
            kubectl logs -n monet-app $MISBEHAVING_POD --tail=50 || true
            
            echo "Checking pod details for $MISBEHAVING_POD:"
            kubectl describe pod -n monet-app $MISBEHAVING_POD || true
          fi
          
          echo "Current services:"
          kubectl get services --all-namespaces || true
          
          echo "Current ingresses:"
          kubectl get ingresses --all-namespaces || true
          
          # Attempt to patch the nginx-ingress controller to disable PROXY protocol for challenge paths
          echo "Patching NGINX ingress controller configuration to disable PROXY protocol for ACME challenges..."
          NGINX_CONFIGMAP_EXISTS=$(kubectl get configmap -n ingress-nginx ingress-nginx-controller 2>/dev/null || echo "")
          
          if [[ -n "$NGINX_CONFIGMAP_EXISTS" ]]; then
            echo "Patching NGINX ConfigMap to disable PROXY protocol for ACME challenges"
            kubectl patch configmap -n ingress-nginx ingress-nginx-controller --type=merge -p '{"data":{"use-proxy-protocol":"false"}}' || true
            
            # Restart NGINX ingress controller to apply new config
            kubectl rollout restart deployment -n ingress-nginx nginx-ingress-ingress-nginx-controller || true
          else
            echo "NGINX ConfigMap not found - creating config with PROXY protocol disabled for ACME challenges"
            cat <<EOF | kubectl apply -f -
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: ingress-nginx-controller
            namespace: ingress-nginx
          data:
            use-proxy-protocol: "false"
          EOF
          fi

      - name: Upload and Register Base Model in MLflow
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.DO_SPACES_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.DO_SPACES_SECRET_KEY }}
          AWS_REGION: ${{ secrets.DO_SPACES_REGION }}
          MLFLOW_S3_ENDPOINT_URL: "https://${{ secrets.DO_SPACES_REGION }}.digitaloceanspaces.com"
          MLFLOW_TRACKING_URI: "https://${{ secrets.MLFLOW_DOMAIN }}"
          MLFLOW_USERNAME: ${{ secrets.MLFLOW_USERNAME }}
          MLFLOW_PASSWORD: ${{ secrets.MLFLOW_PASSWORD }}
        run: |
          pip install boto3 mlflow
          python scripts/upload_base_model.py photo2monet_cyclegan.pt \
            --model-name style_transfer_photo2monet_cyclegan \
            --aliases base prod

      - name: Wait and Verify Deployment
        timeout-minutes: 15
        run: |
          echo "Waiting for services to initialize..."
          # Increase waiting time to 3 minutes to give cert-manager more time to complete challenges
          sleep 180
          
          echo "Installing required packages for verification..."
          pip install requests urllib3
          
          echo "Running deployment verification..."
          export KUBECONFIG=${{ github.workspace }}/.kube/kubeconfig.yaml
          
          # Determine namespaces to verify
          NAMESPACES="monet-app"
          if [[ "${{ secrets.DEPLOY_MLFLOW }}" == "true" ]]; then
            NAMESPACES="$NAMESPACES,mlflow"
            echo "Verifying both monet-app and mlflow namespaces"
          else
            echo "Only verifying monet-app namespace (MLflow not deployed)"
          fi
          
          python scripts/verify_deployment.py --timeout 600 --skip-wait --namespaces $NAMESPACES
          
          echo "Verification complete!"
          
          echo "You can access the application at:"
          echo "- Monet App: https://${{ env.APP_DOMAIN }}"
          if [[ "${{ secrets.DEPLOY_MLFLOW }}" == "true" ]]; then
            echo "- MLflow: https://${{ env.MLFLOW_DOMAIN }}"
          fi

      # - name: Debug Web App CrashLoopBackOff
      #   run: |
      #     export KUBECONFIG=${{ github.workspace }}/.kube/kubeconfig.yaml
          
      #     echo "Checking web app logs to diagnose crash:"
      #     POD_NAME=$(kubectl get pods -n monet-app -l app=monet-web-app --field-selector=status.phase=Running -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
          
      #     if [ -z "$POD_NAME" ]; then
      #       echo "No running web app pod found, trying to get logs from any state pod..."
      #       POD_NAME=$(kubectl get pods -n monet-app -l app=monet-web-app -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
      #     fi
          
      #     if [ -n "$POD_NAME" ]; then
      #       echo "Getting logs for pod $POD_NAME:"
      #       kubectl logs -n monet-app $POD_NAME --previous || kubectl logs -n monet-app $POD_NAME || echo "No logs available"
            
      #       echo "Checking pod details:"
      #       kubectl describe pod -n monet-app $POD_NAME || echo "Could not describe pod"
      #     else
      #       echo "No web app pods found"
      #     fi
          
      #     echo "Checking persistent volume claim status:"
      #     kubectl get pvc -n monet-app || echo "No PVCs found"
          
      #     echo "Checking if model storage is working:"
      #     kubectl describe pvc -n monet-app models-storage || echo "Could not describe PVC" 